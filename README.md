# Task 6 – K-Nearest Neighbors (KNN) Classification

### Objective
Implement and understand KNN algorithm using the Iris dataset.

### Steps
1. Loaded Kaggle Iris dataset.
2. Normalized the features using StandardScaler.
3. Trained KNN for multiple K values (1–20).
4. Evaluated model using accuracy and confusion matrix.
5. Visualized decision boundaries.
6. Performed cross-validation for robust accuracy.

### Tools Used
- Python
- Pandas, Scikit-learn, Matplotlib, NumPy

### Results
- Best K ≈ 5–7 with ≈ 97–100% accuracy.
- Random noise sensitivity observed for small K.
- Normalization improved distance-based performance.
